---
title: "Prior (and likelihood) sensitivity analysis with `priorsense`"
author: 
 - Noa Kallioinen
 - "Topi Paananen"
 - "Paul-Christian BÃ¼rkner"
 - "Aki Vehtari"
 - Aalto University & Cluster of Excellence SimTech, Stuttgart
format: revealjs
project:
  type: website
  output-dir: docs
---

# Overview

```{r, message=FALSE}
options(digits = 2)

library(priorsense)
library(posterior)
library(brms)
library(ggplot2)
library(dplyr)
library(bayesplot)

#color_scheme_set("viridis")
bayesplot_theme_update(text = element_text(size = 20, family = "sans"))

fix_size <- function(p, size = 2, linewidth = 1.5) {
  p$layers[[1]]$aes_params$size <- size   
  p$layers[[2]]$aes_params$size <- 1.5
  #p$layers[[3]]$aes_params$size <- size

  p$layers[[1]]$aes_params$linewidth <- linewidth
  p$layers[[2]]$aes_params$linewidth <- linewidth
  #p$layers[[3]]$aes_params$linewidth <- linewidth
  
  p
}

set.seed(1234)
```

-   Motivation
-   What is `priorsense`?
-   Workflow examples
-   Technical details
-   Closing remarks

# Motivation

::: incremental
-   Choosing priors can be hard and time consuming
-   Default or template weakly-informative priors save time
-   Important to check prior influence on posterior (in relation to likelihood)
-   Semi-automated checks would improve the current (often ad hoc) workflow
:::

# What is `priorsense`?

::: incremental
-   R package
-   tools for semi-automated prior and likelihood sensitivity checks
-   checks sensitivity based on "power-scaling"
    - $p(\theta \mid y) \propto p(\theta)^{\alpha}p(y \mid \theta)$
    -   (varying strength of prior or likelihood)
-   visual checks and numerical diagnostic
-   currently works with rstan, cmdstanr and brms models
:::


## Diagnosing sensitivity with priorsense

|             |     |                       |                           |
|-------------|-----|-----------------------|---------------------------|
|             |          | Prior sensitivity     |                |
|             |          | No                    | Yes                       |
| Likelihood sensitivity | No  |  -                    | Weak likelihood           |
|                        | Yes | Likelihood domination | Prior-likelihood conflict |


# Workflow examples

Using `brms`, `bayesplot` and `priorsense`

https://github.com/paul-buerkner/brms

https://mc-stan.org/bayesplot/

## Plant growth: model

- Goal: model weight (y) of harvested plants depending on control (X = 0) vs nutrition enriching treatment (X = 1)
- Data: 20 observations of harvest weight (10 control, 10 treatment)

```{r}
data("PlantGrowth")

pg <- tibble(PlantGrowth) |>
  filter(group != "trt2")
```

. . .

`weight ~ 1 + group`

. . .

$$
y \sim \text{normal}(\mu, \sigma) \\
\mu = \beta_{\text{Intercept}} + \beta_{\text{grouptrt1}}X \\
\sigma \sim p(\sigma), 
\beta_{\text{Intercept}} \sim p(\beta_{\text{Intercept}}), 
\beta_{\text{grouptrt1}} \sim p(\beta_{\text{grouptrt1}})
$$

## Plant growth: Choosing a prior

- Try weakly informative prior $\beta_{\text{grouptrt1}} \sim \text{normal}(0, 2.5)$ and prior-predictive check

. . .

```{r, message=FALSE, results='hide'}
plantgrowth_fit_prior <- brms::brm(
  weight ~ group,
  data = pg,
  prior = prior(normal(0, 2.5), class = "b"),
  backend = "cmdstanr",
  refresh = 0,
  sample_prior = "only"
  )

plantgrowth_fit <- brms::brm(
  weight ~ group,
  data = pg,
  prior = prior(normal(0, 2.5), class = "b"),
  backend = "cmdstanr",
  refresh = 0)
```

```{r, message=FALSE}
#p <- pp_check(plantgrowth_fit_prior, type = "intervals_grouped", group = "group")

p_min <- pp_check(plantgrowth_fit_prior, type = "stat", stat = "min")
p_median <- pp_check(plantgrowth_fit_prior, type = "stat", stat = "median")
p_max <- pp_check(plantgrowth_fit_prior, type = "stat", stat = "max")

p_min

#fix_size(p_min, linewidth = 4, size = 5)
#fix_size(p_mean, linewidth = 4, size = 5)
#fix_size(p_max, linewidth = 4, size = 5)
```

## Plant growth: Choosing a prior

- Try weakly informative prior $\beta_{\text{grouptrt1}} \sim \text{normal}(0, 2.5)$ and prior-predictive check


```{r}
p_median
```

## Plant growth: Choosing a prior

- Try weakly informative prior $\beta_{\text{grouptrt1}} \sim \text{normal}(0, 2.5)$ and prior-predictive check


```{r}
p_max

```


## Plant growth: Posterior

```{r, message=FALSE}
bayesplot::mcmc_areas(plantgrowth_fit, "b_grouptrt1")

```

## Plant growth: Visual sensitivity check

```{r, echo = FALSE}

plant_ps <- priorsense::powerscale_sensitivity(
  plantgrowth_fit
)

plant_pseq <- powerscale_sequence(plantgrowth_fit)
powerscale_plot_dens(plant_pseq, variables = c("b_grouptrt1"), mcse = TRUE) +
  theme_classic() +
  guides(linetype = "none") +
  theme(plot.title = element_blank(), plot.subtitle = element_blank(), text = element_text(size = 20))
```

## Plant growth: Visual sensitivity check

```{r}
p2 <- powerscale_plot_quantities(
  plant_pseq,
  variables = c("b_grouptrt1"),
  quantities = c("mean", "sd"),
  mcse = TRUE
) +
  theme_classic() +
  guides(color = "none") +
  theme(plot.title = element_blank(),
        plot.subtitle = element_blank(),
        text = element_text(size = 20),
        aspect.ratio = 1)

p2
```

## Plant growth: Sensitivity diagnostic

Checking for sensitivity > 0.05

```{r, eval = TRUE, echo = FALSE}
knitr::kable(priorsense::powerscale_sensitivity(plantgrowth_fit)$sensitivity, digits = 2)
```

## NPK: model

-   Goal: Model effect of Nitrogen, Phosphate and Potassium on pea crop yield
-   Data: 24 observations of crop yield (3 observations of each combination)

. . .

`yield ~ 1 + N * P * K`

. . .

$$
y \sim \beta_{\text{Intercept}} + \beta_{\text{N1}} + \beta_{\text{P1}} + \beta_{\text{K1}} + \beta_{\text{N1:K1}} + \\ \beta_{\text{N1:P1}} + \beta_{\text{K1:P1}} + \beta_{\text{N1:P1:K1}} \\
\sigma \sim p(\sigma), \beta_{\text{Intercept}} \sim p(\beta_{\text{Intercept}}) \\
\beta_i \sim p(\beta_i) 
$$

```{r, echo=FALSE, eval=TRUE, message=FALSE, results='hide'}
data(npk)

npk_fit_prior <- brm(
  yield ~ N * P * K,
  prior = c(
    prior(normal(0, 2.5), class = "b")
    ),
  data = npk,
  backend = "cmdstanr",
  refresh = 0,
  sample_prior = "only"
)
```

## NPK: Choosing a prior

Try $\beta_i \sim \text{normal}(0, 2.5)$ and perform a prior predictive check

. . .

```{r, message=FALSE}

#p <- pp_check(npk_fit_prior, type = "intervals")
pnpk_min <- pp_check(npk_fit_prior, type = "stat", stat = "min")
pnpk_median <- pp_check(npk_fit_prior, type = "stat", stat = "median")
pnpk_max <- pp_check(npk_fit_prior, type = "stat", stat = "max")


#fix_size(p, linewidth = 4, size = 5)

pnpk_min

```

## NPK: Choosing a prior

Try $\beta_i \sim \text{normal}(0, 2.5)$ and perform a prior predictive check

```{r}
pnpk_median
```

## NPK: Choosing a prior

Try $\beta_i \sim \text{normal}(0, 2.5)$ and perform a prior predictive check

```{r}
pnpk_max
```


## NPK: Posterior

```{r, message=FALSE, results='hide'}
npk_fit <- brm(
  yield ~ N * P * K,
  prior = c(
    prior(normal(0, 2.5), class = "b")
    ),
  data = npk,
  backend = "cmdstanr",
  refresh = 0
)

mcmc_plot(npk_fit, variable = c("b_N", "b_P", "b_K"), regex = TRUE, inner_size = 2, outer_size = 1, point_size = 5)

```

## NPK: Sensitivity diagnostic

```{r, echo=FALSE, message=FALSE}
knitr::kable(powerscale_sensitivity(npk_fit, variable = c("b_N", "b_P", "b_K"), regex = TRUE)$sensitivity, digits = 2)

```

## NPK: Visual sensitivity check

```{r}
pseq <- powerscale_sequence(npk_fit)

powerscale_plot_dens(pseq, variables = c("b_N1", "b_N1:P1:K1")) +
  theme_classic() +
  guides(linetype = "none") +
  theme(
    plot.title = element_blank(),
    plot.subtitle = element_blank(),
    text = element_text(size = 20)
  )
```

## NPK: Visual sensitivity check

```{r}
powerscale_plot_quantities(pseq, variables = c("b_N1"),
                           quantities = c("mean", "sd"),
                           mcse = TRUE
) +
  theme_classic() +
  guides(color = "none") +
  theme(
    plot.title = element_blank(),
    plot.subtitle = element_blank(),
    text = element_text(size = 20),
    aspect.ratio = 1
  )
```

## NPK: Adjusted prior

Trying a wider prior: $\beta_i \sim \text{normal}(0, 40)$

. . .

```{r, message=FALSE, results='hide'}

npk_fit2_prior <- brm(
  yield ~ N * P * K,
  prior = prior(normal(0, 40), class = "b"),
  data = npk,
  backend = "cmdstanr",
  refresh = 0,
  sample_prior = "only"
)

npk_fit2 <- brm(
  yield ~ N * P * K,
  prior = prior(normal(0, 40), class = "b"),
  data = npk,
  backend = "cmdstanr",
  refresh = 0
)

mcmc_plot(npk_fit2, variable = c("b_N", "b_P", "b_K"),
          regex = TRUE, inner_size = 2, outer_size = 1, point_size = 5)
```

## NPK: Adjusted prior

```{r}
knitr::kable(powerscale_sensitivity(npk_fit2, variable = c("b_N", "b_P", "b_K"), regex = TRUE)$sensitivity, digits = 2)
```

<!-- ## NPK: Adjusted prior -->

<!-- ```{r} -->
<!-- pseq2 <- powerscale_sequence(npk_fit2) -->

<!-- powerscale_plot_quantities(pseq2, quantities = c("mean", "sd"), variables = c("b_N1"), -->
<!--                            mcse = TRUE) + -->
<!--   theme_classic() + -->
<!--   guides(color = "none") + -->
<!--   theme( -->
<!--     plot.title = element_blank(), -->
<!--     plot.subtitle = element_blank(), -->
<!--     text = element_text(size = 20), -->
<!--     aspect.ratio = 1 -->
<!--   ) -->
<!-- ``` -->

# Technical details

## What's happening in the background?

-   Power-scaling: $p(\theta \mid y) \propto p(\theta)^{\alpha}p(y \mid \theta)$
-   Importance sampling to estimate resulting posterior (base posterior as proposal, modified posterior as target)
-   Importance weights derived from prior or likelihood evaluations
-   Pareto-smoothed importance sampling[^3] and importance weighted moment matching improve estimations[^4]

[^3]: Vehtari et al. 2022 "Pareto-smoothed importance sampling", arxiv:1507.02646

[^4]: Paananen et al. 2021 "Implicitly adaptive importance sampling", Statistics and Computing


## Package details

`priorsense` functions:

-   `powerscale_sensitivity`
-   `powerscale_sequence`
-   `powerscale_plot_*` (`dens`, `ecdf`, `quantities`)

Required Stan code

```{stan, eval=FALSE, echo=TRUE, output.var='stanmodel'}

generated quantities {
  real lprior;
  lprior = normal_lpdf(b | 0, 2.5) + normal_lpdf(sigma | 0, 10);
}

```

## Closing remarks

-   `priorsense` enables efficient and semi-automated sensitivity analysis in R
-   Python version coming soon to ArviZ
-   Sensitivity is not always a problem; think carefully when you observe sensitivity
-   For further details see Kallioinen et al. 2022 "Detecting and diagnosing prior and likelihood sensitivity with power-scaling" `arxiv:2107.14054`
-   **github.com/n-kall/priorsense**

